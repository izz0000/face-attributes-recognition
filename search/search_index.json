{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Overview","text":""},{"location":"#1-introduction","title":"1. Introduction","text":"<ul> <li>Face Attributes Recognition application of machine learning aimed at automatically extracting essential demographic information from human faces which can for analyzing market, and leading marketing decisions.</li> <li>The primary objectives of this project are to develop a robust model capable of accurately identifying the age, gender, and ethnicity of individuals from facial images.</li> <li>This documentation provides an in-depth overview of the methodology, data preprocessing, model architecture, training process, and evaluation metrics employed in achieving these objectives.</li> </ul>"},{"location":"#2-problem-statement","title":"2. Problem Statement","text":"<ul> <li>Despite advancements in computer vision, accurately inferring demographic attributes from facial images remains challenging due to variations in facial expressions, lighting conditions, and image quality.</li> <li>The project aims to address these challenges by leveraging machine learning techniques to build a reliable and efficient face's attributes recognition system.</li> </ul>"},{"location":"#3-data","title":"3. Data","text":"<ul> <li>The UTK Face dataset serves as the primary data source for this project, providing over 20,000 face images annotated with age, gender, and ethnicity attributes.</li> <li>This dataset covers a broad age range from 0 to 116 years old and exhibits diverse variations in pose, facial expression, illumination, occlusion, resolution, etc.</li> <li>After preprocessing steps, such as removing grayscale images and those with missing labels, the UTK Face dataset was deemed suitable for training and evaluating the face's attributes recognition model.</li> </ul>"},{"location":"#4-model-architecture","title":"4. Model Architecture","text":"<ul> <li>The model architecture is designed to extract high-level features from facial images using convolutional neural networks (CNNs) while incorporating techniques like transfer learning to improve performance.</li> <li>Specialized modules are incorporated to handle multitask learning, allowing the model to simultaneously predict age, gender, and ethnicity attributes.</li> </ul>"},{"location":"#5-training-process","title":"5. Training Process","text":"<ul> <li>The training process involves optimizing the model parameters using suitable loss functions and optimization algorithms.</li> <li>Techniques such as hyperparameter tuning are employed to maximize model performance while preventing overfitting and improving generalization.</li> </ul>"},{"location":"#6-evaluation-metrics","title":"6. Evaluation Metrics","text":"<ul> <li>The performance of the model is evaluated using various metrics tailored to each attribute, including accuracy, precision, recall, F1-score, and R<sup>2</sup>.</li> <li>Comprehensive testing is conducted on both validation and unseen test datasets to assess the model's robustness and reliability in real-world scenarios.</li> </ul> <p>Written by: Izadean Ahmed - Revised by: ChatGPT</p>"},{"location":"how-to-use/","title":"How To Use","text":""},{"location":"how-to-use/#training-a-model","title":"Training a Model","text":"<ol> <li>Fill <code>KAGGLE_USERNAME</code> &amp; <code>KAGGLE_KEY</code> environment variables in <code>.env</code> file</li> <li>Run in your terminal: <code>python src/train.py [your training arguments as following]</code></li> </ol>"},{"location":"how-to-use/#training-parameters","title":"Training Parameters","text":"Parameter Description Data Type / Choices Default output-layer-depth number of the FC layers before end int 4 backbone the pretrained backbone of the model <code>mobilenet-v3</code>, <code>resnet50</code>, <code>inception3</code>, <code>efficientnet</code>, <code>densenet121</code> <code>vgg16</code> <code>mobilenet-v3</code> data-dir path of data folder string <code>../data/</code> batch-size the known batch size int 32 accelerator computation device <code>cpu</code>, <code>gpu</code>, or <code>tpu</code> <code>gpu</code> if available precision float precision mode <code>transformer-engine</code>, <code>transformer-engine-float16</code>, <code>16-true</code>, <code>16-mixed</code>, <code>bf16-true</code>, <code>bf16-mixed</code>, <code>32-true</code>, <code>64-true</code> depends on the model epochs the known epochs int 5 learning-rate the known learning rate float 0.001 num-workers the number of processes that loads the data in parallel int 2 optimizer the known optimizer <code>adam</code>, <code>sgd</code>, <code>rmsprop</code> <code>adam</code>"},{"location":"how-to-use/#predict-from-image","title":"Predict from Image","text":"<ol> <li>Get trained model id</li> <li>Run in your terminal: <code>python src/predict.py &lt;your_model_id&gt; &lt;your_image_path&gt;</code></li> </ol>"}]}